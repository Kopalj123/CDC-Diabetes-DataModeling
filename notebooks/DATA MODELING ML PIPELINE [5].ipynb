{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA MODELING ML PIPELINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read & Store Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.read_csv('DiabetesCleaned_2018.csv', index_col=0) # Read csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df_clean.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52851 is the length of all_ones\n",
      "336717 is the length of all_zeros\n"
     ]
    }
   ],
   "source": [
    "all_ones  = df_clean.loc[df_model['DIABETES'] == 1]\n",
    "all_zeros = df_clean.loc[df_model['DIABETES'] == 0]\n",
    "\n",
    "print(\"{} is the length of all_ones\".format(len(all_ones)))\n",
    "print(\"{} is the length of all_zeros\".format(len(all_zeros)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000 is the length of sampled_ones\n",
      "30000 is the length of samples_zeros\n"
     ]
    }
   ],
   "source": [
    "sampled_ones = all_ones.sample(n=30000)\n",
    "samples_zeros = all_zeros.sample(n=30000)\n",
    "\n",
    "print(\"{} is the length of sampled_ones\".format(len(sampled_ones)))\n",
    "print(\"{} is the length of samples_zeros\".format(len(samples_zeros)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = pd.concat((sampled_ones, samples_zeros), axis=0)\n",
    "df_model = df_model.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 60000 entries, 283235 to 133961\n",
      "Data columns (total 19 columns):\n",
      "EXERCISE                60000 non-null float64\n",
      "HEARTATTACK             60000 non-null float64\n",
      "CORONARYHEARTDISEASE    60000 non-null float64\n",
      "STROKE                  60000 non-null float64\n",
      "ASTHMA                  60000 non-null float64\n",
      "SKINCANCER              60000 non-null float64\n",
      "OTHERCANCER             60000 non-null float64\n",
      "CHRONICBRONCHITIS       60000 non-null float64\n",
      "ARTHRITIS               60000 non-null float64\n",
      "DEPRESSIVEDISORDER      60000 non-null float64\n",
      "KIDNEYDISEASE           60000 non-null float64\n",
      "DIABETES                60000 non-null float64\n",
      "SLEEPTIME_GROUP         60000 non-null object\n",
      "SEX_GROUP               60000 non-null object\n",
      "WEIGHT_KILOGRAM         60000 non-null float64\n",
      "HEIGHT_METER            60000 non-null float64\n",
      "BMI_GROUP               60000 non-null object\n",
      "RACE_GROUP              60000 non-null object\n",
      "AGE_GROUP               60000 non-null object\n",
      "dtypes: float64(14), object(5)\n",
      "memory usage: 9.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_model.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Data (Independent Variables & Depedent Varaibles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations and dimensions in 'X': (60000, 18)\n",
      "Number of observations in 'y': (60000,)\n"
     ]
    }
   ],
   "source": [
    "dependentVar = 'DIABETES'\n",
    "\n",
    "X = df_model.loc[:, df_model.columns != dependentVar]\n",
    "y = df_model[dependentVar].values\n",
    "\n",
    "print(\"Number of observations and dimensions in 'X':\", X.shape)\n",
    "print(\"Number of observations in 'y':\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        EXERCISE  HEARTATTACK  CORONARYHEARTDISEASE  STROKE  ASTHMA  \\\n",
      "283235       0.0          0.0                   0.0     0.0     0.0   \n",
      "265051       0.0          1.0                   0.0     0.0     1.0   \n",
      "374463       0.0          0.0                   0.0     0.0     0.0   \n",
      "156849       1.0          0.0                   0.0     0.0     0.0   \n",
      "32830        1.0          0.0                   1.0     0.0     0.0   \n",
      "...          ...          ...                   ...     ...     ...   \n",
      "143113       1.0          0.0                   0.0     0.0     0.0   \n",
      "399750       1.0          0.0                   0.0     0.0     0.0   \n",
      "250087       1.0          0.0                   0.0     0.0     0.0   \n",
      "414675       1.0          0.0                   0.0     0.0     0.0   \n",
      "133961       1.0          1.0                   1.0     0.0     0.0   \n",
      "\n",
      "        SKINCANCER  OTHERCANCER  CHRONICBRONCHITIS  ARTHRITIS  \\\n",
      "283235         0.0          1.0                0.0        0.0   \n",
      "265051         0.0          1.0                0.0        0.0   \n",
      "374463         0.0          0.0                0.0        0.0   \n",
      "156849         0.0          1.0                0.0        1.0   \n",
      "32830          0.0          0.0                0.0        0.0   \n",
      "...            ...          ...                ...        ...   \n",
      "143113         0.0          0.0                0.0        0.0   \n",
      "399750         0.0          0.0                0.0        0.0   \n",
      "250087         0.0          0.0                0.0        0.0   \n",
      "414675         0.0          0.0                0.0        1.0   \n",
      "133961         0.0          0.0                1.0        0.0   \n",
      "\n",
      "        DEPRESSIVEDISORDER  KIDNEYDISEASE SLEEPTIME_GROUP SEX_GROUP  \\\n",
      "283235                 1.0            0.0       LessSleep    Female   \n",
      "265051                 0.0            1.0     NormalSleep    Female   \n",
      "374463                 0.0            0.0       LessSleep    Female   \n",
      "156849                 0.0            1.0       LessSleep      Male   \n",
      "32830                  1.0            0.0       LessSleep      Male   \n",
      "...                    ...            ...             ...       ...   \n",
      "143113                 0.0            0.0     NormalSleep      Male   \n",
      "399750                 0.0            0.0       LessSleep    Female   \n",
      "250087                 0.0            0.0     NormalSleep    Female   \n",
      "414675                 0.0            0.0       LessSleep      Male   \n",
      "133961                 1.0            1.0       LessSleep      Male   \n",
      "\n",
      "        WEIGHT_KILOGRAM  HEIGHT_METER     BMI_GROUP RACE_GROUP AGE_GROUP  \n",
      "283235           77.111         1.524         Obese      White   Elderly  \n",
      "265051           88.450         1.626         Obese      White   Elderly  \n",
      "374463           81.647         1.626         Obese   Hispanic     Adult  \n",
      "156849           96.162         1.778         Obese      White  OldAdult  \n",
      "32830            74.843         1.854  NormalWeight      White     Adult  \n",
      "...                 ...           ...           ...        ...       ...  \n",
      "143113           98.883         1.829    OverWeight      White   Elderly  \n",
      "399750           58.513         1.626  NormalWeight      White   Elderly  \n",
      "250087           78.925         1.702    OverWeight      Black     Adult  \n",
      "414675           80.739         1.753    OverWeight      White  OldAdult  \n",
      "133961           88.904         1.626         Obese      White   Elderly  \n",
      "\n",
      "[60000 rows x 18 columns] \n",
      "\n",
      "[1. 0. 0. ... 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(X, '\\n')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Data (Train & Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations and dimensions in training set: (45000, 18)\n",
      "Number of observations and dimensions in test set: (15000, 18)\n",
      "Number of observations in training set: (45000,)\n",
      "Number of observations in test set: (15000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "print(\"Number of observations and dimensions in training set:\", X_train.shape)\n",
    "print(\"Number of observations and dimensions in test set:\", X_test.shape)\n",
    "print(\"Number of observations in training set:\", y_train.shape)\n",
    "print(\"Number of observations in test set:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['SLEEPTIME_GROUP', 'SEX_GROUP', 'BMI_GROUP', 'RACE_GROUP', 'AGE_GROUP']\n",
    "numerical_features   = [col for col in X.columns if col not in categorical_features]\n",
    "preprocessor         = ColumnTransformer(\n",
    "                        transformers=[('onehot-encoder', OneHotEncoder(), categorical_features),\n",
    "                                     ('scalar', StandardScaler(), numerical_features)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "pipeline_lr = Pipeline([('preprocessor', preprocessor),\n",
    "                        ('pca', PCA(n_components=2)),\n",
    "                        ('lr_classifier', LogisticRegression(class_weight='balanced', random_state=1234))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "pipeline_knn = Pipeline([('preprocessor', preprocessor),\n",
    "                        ('pca', PCA(n_components=2)),\n",
    "                        ('knn_classifier', KNeighborsClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "pipeline_svc = Pipeline([('preprocessor', preprocessor),\n",
    "                        ('pca', PCA(n_components=2)),\n",
    "                        ('svc_classifier', SVC(class_weight='balanced', random_state=1234))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "pipeline_nb = Pipeline([('preprocessor', preprocessor),\n",
    "                        ('pca', PCA(n_components=2)),\n",
    "                        ('nb_classifier', GaussianNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "pipeline_dt = Pipeline([('preprocessor', preprocessor),\n",
    "                     ('pca', PCA(n_components=2)),\n",
    "                     ('dt_classifier', DecisionTreeClassifier(class_weight='balanced', random_state=1234))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "pipeline_rf = Pipeline([('preprocessor', preprocessor),\n",
    "                     ('pca', PCA(n_components=2)),\n",
    "                     ('rf_classifier', RandomForestClassifier(class_weight='balanced', random_state=1234))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "pipeline_xgb = Pipeline([('preprocessor', preprocessor),\n",
    "                     ('pca', PCA(n_components=2)),\n",
    "                     ('xgb_classifier', XGBClassifier(class_weight='balanced', random_state=1234))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "pipeline_adb = Pipeline([('preprocessor', preprocessor),\n",
    "                     ('pca', PCA(n_components=2)),\n",
    "                     ('adb_classifier', AdaBoostClassifier(random_state=1234))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Pipeline on Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = [pipeline_lr, pipeline_knn, pipeline_svc, pipeline_nb, pipeline_dt, pipeline_rf, pipeline_xgb, \n",
    "             pipeline_adb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_dict = {0: 'Logistic Regression', 1: 'K-Nearest Neighbors', 2: 'Kernal Support Vector Machine',  \n",
    "             3: 'Naive Bayes', 4: 'Decision Tree', 5: 'Random Forest', 6: 'XGBoost', 7: 'AdaBoost'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "for pipe in pipelines:\n",
    "\tpipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict Pipeline on Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test Accuracy: 0.666\n",
      "K-Nearest Neighbors Test Accuracy: 0.632\n",
      "Kernal Support Vector Machine Test Accuracy: 0.667\n",
      "Naive Bayes Test Accuracy: 0.644\n",
      "Decision Tree Test Accuracy: 0.600\n",
      "Random Forest Test Accuracy: 0.623\n",
      "XGBoost Test Accuracy: 0.676\n",
      "AdaBoost Test Accuracy: 0.673\n"
     ]
    }
   ],
   "source": [
    "for i,model in enumerate(pipelines):\n",
    "    print(\"{0:s} Test Accuracy: {1:.3f}\".format(pipe_dict[i], model.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier with best accuracy: XGBoost\n"
     ]
    }
   ],
   "source": [
    "best_accuracy   = 0\n",
    "best_classifier = 0\n",
    "best_pipeline   = \"\"\n",
    "\n",
    "for i,model in enumerate(pipelines):\n",
    "    if model.score(X_test,y_test) > best_accuracy:\n",
    "        best_accuracy = model.score(X_test,y_test)\n",
    "        best_pipeline = model\n",
    "        best_classifier = i\n",
    "print('Classifier with best accuracy: {}'.format(pipe_dict[best_classifier]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "param_grid_lr = {\n",
    "    'lr_classifier__max_iter': [100, 200, 500, 1000],                              # Number of iterations\n",
    "    'lr_classifier__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],   # Algorithm to use for optimization\n",
    "    'lr_classifier__class_weight': ['balanced']                                    # Troubleshoot unbalanced data sampling\n",
    "}\n",
    "\n",
    "gdLR = GridSearchCV(estimator=pipeline_lr, param_grid=param_grid_lr, cv=3, n_jobs=-1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_knn = {\n",
    "    'knn_classifier__n_neighbors': [5, 10, 15],                                      # Number of K\n",
    "    #'knn_classifier__algorithm': ['ball_tree', 'kd_tree', 'brute', 'auto'],         # Algorithm to compute nearest neighbors\n",
    "    'knn_classifier__metric': ['minkowski', 'euclidean', 'manhattan', 'chebyshev']   # Algorithm to find the distance\n",
    "}\n",
    "\n",
    "gdKNN = GridSearchCV(estimator=pipeline_knn, param_grid=param_grid_knn, cv=3, n_jobs=-1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_svc = {\n",
    "    'svc_classifier__C': [0.1, 1, 10, 100],                           # Regularization parameter\n",
    "    'svc_classifier__gamma': [1, 0.1, 0.01, 0.001],                   # Kernel coef for ‘rbf’, ‘poly’ and ‘sigmoid’\n",
    "    #'svc_classifier__kernel': ['linear', 'rbf', 'poly', 'sigmoid'],  # Kernel type to be used in the algorithm\n",
    "    #'svc_classifier__degree': [1, 2, 3, 4, 5, 6],                    # Degree for ‘poly’\n",
    "    'svc_classifier__class_weight': ['balanced']                      # Troubleshoot unbalanced data sampling\n",
    "}\n",
    "\n",
    "gdSVC = GridSearchCV(estimator=pipeline_svc, param_grid=param_grid_svc, cv=2, n_jobs=-1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_dt = {\n",
    "    'dt_classifier__criterion': ['gini', 'entropy'],   # Measure quality of split\n",
    "    'dt_classifier__splitter': ['best', 'random'],     # Strategy used to choose split at each node\n",
    "    'dt_classifier__max_depth': [2, 4, 6, 8, 10],      # Maximum depth of the tree\n",
    "    'dt_classifier__class_weight': ['balanced']        # Troubleshoot unbalanced data sampling\n",
    "}\n",
    "\n",
    "gdDT = GridSearchCV(estimator=pipeline_dt, param_grid=param_grid_dt, cv=3, n_jobs=-1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_rf = {\n",
    "    'rf_classifier__criterion': ['gini', 'entropy'],        # Measure quality of split\n",
    "    'rf_classifier__max_depth': [2, 3, 5, 9],               # Maximum depth of the tree\n",
    "    'rf_classifier__n_estimators': [100, 200, 300, 1000],   # Number of trees in the forest\n",
    "    'rf_classifier__class_weight': ['balanced']             # Troubleshoot unbalanced data sampling\n",
    "}\n",
    "\n",
    "gdRF = GridSearchCV(estimator=pipeline_rf, param_grid=param_grid_rf, cv=3, n_jobs=-1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_xgb = {\n",
    "    'xgb_classifier__max_depth': [2, 3, 5, 9],                   # Maximum depth of a tree\n",
    "    'xgb_classifier__n_estimators': [50, 100, 200, 300, 1000],   # Maximum number of estimators at which boosting is terminated\n",
    "    'xgb_classifier__learning_rate': [1, 0.1, 0.01, 0.001],      # Step size shrinkage used in update to prevents overfitting range: [0,1]\n",
    "    'xgb_classifier__class_weight': ['balanced']                 # Troubleshoot unbalanced data sampling\n",
    "}\n",
    "\n",
    "gdXGB = GridSearchCV(estimator=pipeline_xgb, param_grid=param_grid_xgb, cv=3, n_jobs=-1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_adb = {\n",
    "    'adb_classifier__n_estimators': [50, 100, 200, 300, 1000],   # Maximum number of estimators at which boosting is terminated\n",
    "    'adb_classifier__learning_rate': [1, 0.1, 0.01, 0.001]       # Step size shrinkage used in update to prevents overfitting range: [0,1]   \n",
    "}\n",
    "\n",
    "gdADB = GridSearchCV(estimator=pipeline_adb, param_grid=param_grid_adb, cv=3, n_jobs=-1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Pipeline Grid Search on Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines_grid = [gdLR, gdKNN, gdSVC, gdDT, gdRF, gdXGB, gdADB]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_grid_dict = {0: 'Logistic Regression', 1: 'K-Nearest Neighbors', 2: 'Kernal Support Vector Machine', \n",
    "                  3: 'Decision Tree', 4: 'Random Forest', 5: 'XGBoost', 6: 'AdaBoost'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    5.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:    5.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 16 candidates, totalling 32 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  32 | elapsed:  5.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    2.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   31.8s\n",
      "[Parallel(n_jobs=-1)]: Done  96 out of  96 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 80 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   26.7s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:  5.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   33.1s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  1.2min finished\n"
     ]
    }
   ],
   "source": [
    "for pipe in pipelines_grid:\n",
    "\tpipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict Pipeline Grid Search on Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test Accuracy: 0.666\n",
      "K-Nearest Neighbors Test Accuracy: 0.657\n",
      "Kernal Support Vector Machine Test Accuracy: 0.670\n",
      "Decision Tree Test Accuracy: 0.674\n",
      "Random Forest Test Accuracy: 0.676\n",
      "XGBoost Test Accuracy: 0.676\n",
      "AdaBoost Test Accuracy: 0.674\n"
     ]
    }
   ],
   "source": [
    "for i,model in enumerate(pipelines_grid):\n",
    "    print(\"{0:s} Test Accuracy: {1:.3f}\".format(pipe_grid_dict[i], model.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier with best accuracy: XGBoost\n"
     ]
    }
   ],
   "source": [
    "best_accuracy   = 0\n",
    "best_classifier = 0\n",
    "best_pipeline   = \"\"\n",
    "\n",
    "for i,model in enumerate(pipelines):\n",
    "    if model.score(X_test,y_test) > best_accuracy:\n",
    "        best_accuracy = model.score(X_test,y_test)\n",
    "        best_pipeline = model\n",
    "        best_classifier = i\n",
    "print('Classifier with best accuracy: {}'.format(pipe_dict[best_classifier]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### End of document."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
